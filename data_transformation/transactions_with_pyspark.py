"""
You are given a dataset containing information about customer transactions in a retail store. The dataset is stored in a CSV file named transactions.csv with the following columns:

transaction_id: Unique identifier for each transaction.
customer_id: Unique identifier for each customer.
transaction_date: The date of the transaction in YYYY-MM-DD format.
product_id: Unique identifier for each product.
quantity: The quantity of the product purchased in the transaction.
price: The price of a single unit of the product.

Task 1: Load and Inspect Data
Load the transactions.csv file into a PySpark DataFrame.
Display the schema and the first 5 rows of the DataFrame.

Task 2: Basic Data Analysis
Calculate the total revenue generated by each product.
Identify the top 5 customers who have spent the most money in the store.
Determine the number of transactions made each month.

Task 3: Advanced Data Analysis
For each customer, calculate their average spending per transaction.
Identify the most popular product (the product with the highest total quantity sold) for each month.
Find the top 3 customers for each month based on their total spending.
Calculate the cumulative revenue over time and plot it.
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import (
    col,
    sum as _sum,
    avg,
    month,
    desc,
    row_number,
)
from pyspark.sql.window import Window
import matplotlib.pyplot as plt


# Initialize a Spark session
spark = SparkSession.builder.appName(
    "Retail Transaction Analysis"
).getOrCreate()


# Task 1: Load and Inspect Data

# Load the CSV file into a DataFrame
transactions_df = spark.read.csv(
    "./data/transactions.csv", header=True, inferSchema=True
)


# Display the schema
transactions_df.printSchema()

# Display the first 5 rows
transactions_df.show(5)

# Task 2: Basic Data Analysis

# 1. Calculate the total revenue generated by each product
transactions_df = transactions_df.withColumn(
    "total_price", col("quantity") * col("price")
)

total_revenue_per_product = transactions_df.groupBy("product_id").agg(
    _sum("total_price").alias("total_revenue")
)

# Display the results
total_revenue_per_product.show()

# 2. Identify the top 5 customers who have spent the most money in the store
total_spent_per_customer = transactions_df.groupBy("customer_id").agg(
    _sum("total_price").alias("total_spent")
)
top_5_customers = total_spent_per_customer.orderBy(
    col("total_spent").desc()
).limit(5)

# Display the results
top_5_customers.show()

# 3. Determine the number of transactions made each month
transactions_per_month = (
    transactions_df.withColumn("month", month(col("transaction_date")))
    .groupBy("month")
    .count()
    .alias("transaction_count")
)

# Display the results
transactions_per_month.show()

# Task 3: Advanced Data Analysis

# 1. For each customer, calculate their average spending per transaction
avg_spending_per_customer = transactions_df.groupBy("customer_id").agg(
    avg("total_price").alias("avg_spent_per_transaction")
)

# Display the results
avg_spending_per_customer.show()

# 2. Identify the most popular product (the product with the highest total quantity sold) for each month
monthly_product_sales = (
    transactions_df.withColumn("month", month(col("transaction_date")))
    .groupBy("month", "product_id")
    .agg(_sum("quantity").alias("total_quantity"))
)

window_spec = Window.partitionBy("month").orderBy(desc("total_quantity"))
most_popular_product_per_month = (
    monthly_product_sales.withColumn("rank", row_number().over(window_spec))
    .filter(col("rank") == 1)
    .drop("rank")
)

# Display the results
most_popular_product_per_month.show()

# 3. Find the top 3 customers for each month based on their total spending
monthly_customer_spending = (
    transactions_df.withColumn("month", month(col("transaction_date")))
    .groupBy("month", "customer_id")
    .agg(_sum("total_price").alias("total_spent"))
)

window_spec = Window.partitionBy("month").orderBy(desc("total_spent"))
top_3_customers_per_month = (
    monthly_customer_spending.withColumn(
        "rank", row_number().over(window_spec)
    )
    .filter(col("rank") <= 3)
    .drop("rank")
)

# Display the results
top_3_customers_per_month.show()

# 4. Calculate the cumulative revenue over time and plot it
cumulative_revenue_df = (
    transactions_df.groupBy("transaction_date")
    .agg(_sum("total_price").alias("daily_revenue"))
    .orderBy("transaction_date")
)

cumulative_revenue_df = cumulative_revenue_df.withColumn(
    "cumulative_revenue",
    _sum("daily_revenue").over(Window.orderBy("transaction_date")),
)

# Convert to Pandas DataFrame for plotting
cumulative_revenue_pd = cumulative_revenue_df.toPandas()

# Plot the cumulative revenue over time
plt.figure(figsize=(12, 6))
plt.plot(
    cumulative_revenue_pd["transaction_date"],
    cumulative_revenue_pd["cumulative_revenue"],
    marker="o",
)
plt.xlabel("Date")
plt.ylabel("Cumulative Revenue")
plt.title("Cumulative Revenue Over Time")
plt.grid(True)
plt.show()

# Stop the Spark session
spark.stop()
